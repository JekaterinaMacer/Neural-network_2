{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Сети с вниманием",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uu0tCgpbnH_U"
      },
      "source": [
        "*Теоретический материал:* https://youtu.be/n6vz5OZHKZ8?t=4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcLQYuqcjvYL"
      },
      "source": [
        "# **Import библиотек**\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/n6vz5OZHKZ8?t=789"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETYoDtYnjG6H"
      },
      "source": [
        "from google.colab import files #модуль для загрузки файлов в colab\n",
        "\n",
        "%tensorflow_version 2.x \n",
        "import tensorflow as tf #загружаем версию tensorflow 2.x для корректной работы данного скрипта. Текущая версия по умолчанию - 1.x\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer #загружаем токенизатор кераса для предобработки текстовых данных\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences #метод для формирования последовательностей одинаковой длины\n",
        "from tensorflow.keras.models import Model #загружаем абстрактный класс базовой модели сети от кераса\n",
        "from tensorflow.keras.layers import Dense, Embedding, GRU #из кераса загружаем необходимые слои для нейросети\n",
        "from tensorflow.keras.optimizers import Adam #из кераса загружаем выбранный оптимизатор\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy #из кераса загружаем выбранную функцию потерь\n",
        "import numpy as np #библиотека для работы с массивами данных\n",
        "\n",
        "# Библиотека для визуализации данных\n",
        "import matplotlib.pyplot as plt #интерфейс для построения графиков простых функций\n",
        "import matplotlib.ticker as ticker # модуль для определения форматирования и местоположения делений на осях графиков.\n",
        "\n",
        "from sklearn.model_selection import train_test_split #модуль для разбивки данных на обучающую и тестовую выборки\n",
        "import re #модуль для работы с регулярными выражениями(воспользуемся в предобработке данных)\n",
        "import time #модуль для работы с временем\n",
        "import os #модуль для работы с операционной системой(воспользуемся методами работы с каталогами)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zDsn1WU6BCq"
      },
      "source": [
        "# **Загрузка и парсинг данных**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVI9yFRhRvTw"
      },
      "source": [
        "# Загрузить по ссылке с гугл драйва\n",
        "# path_to_txt = tf.keras.utils.get_file('eng-rus_dictionary.txt', origin='https://drive.google.com/uc?export=download&id=1phlxAS_QBq65_WmadLLIeTqqHArXQbSR')\n",
        "# path_to_file = os.path.dirname(path_to_txt)+\"/eng-rus_dictionary.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O01PTpPmjPpn",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "7b6ee499-7f42-4a28-8f76-86f654655907"
      },
      "source": [
        "files.upload() #загружаем файл с базой(англо-русский словарь)\n",
        "# Базы с различными языками можно скачать здесь http://www.manythings.org/anki/."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-046baa5f-c44e-4eb4-b88b-56f57689531b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-046baa5f-c44e-4eb4-b88b-56f57689531b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving eng-rus_dictionary.txt to eng-rus_dictionary.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFpoO5Gg4Pt_"
      },
      "source": [
        "path_to_file = '/content/eng-rus_dictionary.txt' #указываем путь к загруженному файлу(по умолчанию сохраняется в папке content в левой панели)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gvw1cdz-QSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a090a8d-d005-4834-f8d6-f1176f0b84ea"
      },
      "source": [
        "######################\n",
        "# Предобработка предложений(очищаем от мусора, формируем нужную структуру слов и фраз)\n",
        "######################\n",
        "def preprocess_sentence(phrases): # функция принимает содержимое словаря\n",
        "  # Разделяем пробелами слова и знаки препинания(\"А как насчет тебя? \" -> \"А как насчет тебя ? \") \n",
        "  phrases = re.sub(r\"([?.!,;:])\", r\" \\1 \", phrases) # r\" \\1 \" берёт значения 1й группы в скобках; обрамляем указанные символы пробелами\n",
        "\n",
        "  # Заменяем всё на пробелы, за исключением (a-zA-Zа-яёА-ЯЁ?.!,;:)\n",
        "  phrases = re.sub(r\"[^a-zA-Zа-яёА-ЯЁ?.!,;:]+\", \" \", phrases) # (a-zA-Zа-яёА-ЯЁ) - английский и русский алфавит\n",
        "\n",
        "  phrases = phrases.rstrip().strip() #получаем строку без случайных лишних пробелов в конце фраз(rstrip удаляет с конца строки)\n",
        "  phrases = '<start> ' + phrases + ' <end>' #для нашей модели обозначим тегами начало и конец предложения\n",
        "  return phrases # функция возвращает предобработанные фразы\n",
        "print(\"Фразы после обработки функцией с т.з. пунктуации примут вид:\")\n",
        "print(preprocess_sentence(\"What about you?\"))\n",
        "print(preprocess_sentence(\"А как насчет тебя?\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Фразы после обработки функцией с т.з. пунктуации примут вид:\n",
            "<start> What about you ? <end>\n",
            "<start> А как насчет тебя ? <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2luO-qN-ikY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6a7039f-2649-4d82-d288-0ae7557faa55"
      },
      "source": [
        "def create_dataset(path, num_examples): #функция принимает путь к файлу и выбранное количество пар-фраз из базы, которое возьмем в работу\n",
        "\n",
        "''' Функция возвращает максимальную длину элемента тензора\n",
        "    \n",
        "    Args: \n",
        "        tensor - тензор (фразы в виде последовательности индексов)\n",
        "\n",
        "    Return: \n",
        "        значение максимальной длины его элемента\n",
        "\n",
        "    '''\n",
        "  # Открываем файл и разбиваем фразы на отдельные строчки\n",
        "  lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "  # В каждой строке словаря разделяем английскую фразу от русской, и пропускаем через функцию предобработки данных\n",
        "  word_pairs = [[preprocess_sentence(phrases) for phrases in l.split('\\t')]  for l in lines[:num_examples]]\n",
        "  return zip(*word_pairs) #сцепляем пары фраз в виде [по-английски, по-русски]\n",
        "\n",
        "print(\"Взглянем на пример пары фраз на выходе функции:\")\n",
        "english, russian = create_dataset(path_to_file, None) #вызовем функцию для демонстрации\n",
        "print(english[-1]) #выведем последний элемент из списка английских фраз\n",
        "print(russian[-1]) #выведем последний элемент из списка русских фраз"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Взглянем на пример пары фраз на выходе функции:\n",
            "<start> Doubtless there exists in this world precisely the right woman for any given man to marry and vice versa ; but when you consider that a human being has the opportunity of being acquainted with only a few hundred people , and out of the few hundred that there are but a dozen or less whom he knows intimately , and out of the dozen , one or two friends at most , it will easily be seen , when we remember the number of millions who inhabit this world , that probably , since the earth was created , the right man has never yet met the right woman . <end>\n",
            "<start> Несомненно , для каждого мужчины в этом мире где то есть подходящая женщина , которая может стать ему женой , обратное верно и для женщин . Но если учесть , что у человека может быть максимум несколько сотен знакомых , из которых лишь дюжина , а то и меньше , тех , кого он знает близко , а из этой дюжины у него один или от силы два друга , то можно легко увидеть , что с учётом миллионов живущих на Земле людей , ни один подходящий мужчина , возможно , ещё не встретил подходящую женщину . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def max_length(tensor):  \n",
        "\n",
        "''' Функция возвращает максимальную длину элемента тензора\n",
        "    \n",
        "    Args: \n",
        "        tensor - тензор (фразы в виде последовательности индексов)\n",
        "\n",
        "    Return: \n",
        "        значение максимальной длины его элемента\n",
        "\n",
        "    '''\n",
        "  return max(len(t) for t in tensor) "
      ],
      "metadata": {
        "id": "35n1PvpRmn4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(language):  \n",
        "\n",
        "''' Функция преобразования текстов в последовательности индексов\n",
        "    \n",
        "    Args: \n",
        "        language - текст одного из языков\n",
        "\n",
        "    Return: \n",
        "        tensor - последовательность индексов (назовем ее тензор) \n",
        "        language_tokenizer - переменная, ссылающуюся на токенизатор\n",
        "\n",
        "    '''\n",
        "  \n",
        "  # вызываем класс Токенизатор, просим его не удалять символы, которые он удаляет по умолчанию\n",
        "  language_tokenizer = Tokenizer(filters='') \n",
        "  \n",
        "  # подаем ему тексты для обработки и сборки словаря частотности\n",
        "  language_tokenizer.fit_on_texts(language) \n",
        "  \n",
        "  # разбиваем текст фраз на последовательности индексов\n",
        "  tensor = language_tokenizer.texts_to_sequences(language) \n",
        "  \n",
        "  # делаем последовательности фиксированной длины, заполняя нулями более короткие фразы\n",
        "  tensor = pad_sequences(tensor, padding='post') \n",
        "\n",
        "  return tensor, language_tokenizer  "
      ],
      "metadata": {
        "id": "P8cMIcg-nKve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGUKZI3AaQrl"
      },
      "source": [
        "def load_dataset(path, num_examples=None):  \n",
        "\n",
        "''' Функция формирует итоговый датасет с использованием предыдущих функций\n",
        "    \n",
        "    Args: \n",
        "        path - путь к базе  \n",
        "        num_examples - выбранный объем примеров анг-рус словаря\n",
        "\n",
        "    Return: \n",
        "        input_tensor - тензор для русского языка\n",
        "        target_tensor - ... и английского языка\n",
        "        inp_language_tokenizer - токенизаторы для русского\n",
        "        targ_language_tokenizer - ... и английского языков\n",
        "\n",
        "    '''\n",
        "    \n",
        "    # Из исходного текста делаем датасет пар фраз, причём входным языком для сети сделаем русский\n",
        "    targ_language, inp_language = create_dataset(path, num_examples)\n",
        "\n",
        "    # Разбиваем поток текста на последовательность индексов(назовем ее тензор)\n",
        "    input_tensor, inp_language_tokenizer = tokenize(inp_language) #формируем тензоры и токенизатор для русского языка\n",
        "    target_tensor, targ_language_tokenizer = tokenize(targ_language) #формируем тензоры и токенизатор для английского языка\n",
        "\n",
        "    return input_tensor, target_tensor, inp_language_tokenizer, targ_language_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Zys23c9aDpT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12ea038-5c85-4a22-a6b4-30cf0d55043a"
      },
      "source": [
        "######################\n",
        "# Формирование датасета заданного объема(в зависимости от приоритета скорости либо качества обучения)\n",
        "######################\n",
        "num_examples = 40000 #выберем 40 тысяч строк(всего в базе около 360тысяч строк, в каждой пара фраз)\n",
        "input_tensor, target_tensor, inp_language_tokenizer, targ_language_tokenizer = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Вычислим максимальные длины тензоров для английского и русского языков, используя ранее заданную функцию\n",
        "max_length_targ, max_length_inp = max_length(target_tensor), max_length(input_tensor)\n",
        "\n",
        "# Создаем тренировочную и тестовую выборки по формуле 80/20\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Визуализируем собранные данные\n",
        "def convert(language, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, language.index_word[t]))\n",
        "print (\"Фраза на русском языке; соответствие индекса и слова\")\n",
        "convert(inp_language_tokenizer, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Фраза на английском языке; соответствие индекса и слова\")\n",
        "convert(targ_language_tokenizer, target_tensor_train[0])\n",
        "print ()\n",
        "print(\"Рус.яз. тренировочная: \" , len(input_tensor_train), \"фраз; \", \"Анг.яз. тренировочная: \", len(target_tensor_train), \"фраз\")\n",
        "print(\"Рус.яз. тестовая: \", len(input_tensor_val), \"фраз; \", \"Анг.яз. тестовая: \", len(target_tensor_val), \"фраз\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Фраза на русском языке; соответствие индекса и слова\n",
            "1 ----> <start>\n",
            "4 ----> я\n",
            "71 ----> сделал\n",
            "491 ----> два\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Фраза на английском языке; соответствие индекса и слова\n",
            "1 ----> <start>\n",
            "4 ----> i\n",
            "122 ----> made\n",
            "339 ----> two\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Рус.яз. тренировочная:  32000 фраз;  Анг.яз. тренировочная:  32000 фраз\n",
            "Рус.яз. тестовая:  8000 фраз;  Анг.яз. тестовая:  8000 фраз\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7olSlL4B_pSX"
      },
      "source": [
        "# **Параметры нейросети**\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/n6vz5OZHKZ8?t=1334"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOC2Qi7B5mi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9a2fe80-a901-43df-f6cf-1017b3bcebe9"
      },
      "source": [
        "######################\n",
        "# Создаем tf.data датасет (Раздел tf.data.Dataset API предлагает построить готовый конвейер для обучения моделей)\n",
        "######################\n",
        "# Метод .shuffle с параметром BUFFER_SIZE задаст случайность подачи тренировочных сэмплов в процессе обучения(против переобучения) \n",
        "BUFFER_SIZE = len(input_tensor_train) #укажем что случайно сэмплировать будем по всей длине обучающейся выборки\n",
        "\n",
        "BATCH_SIZE = 64 #указываем размер батча\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE # укажем количество шагов в одной эпохе\n",
        "embedding_dim = 256 #размерность эмбеддинга, векторного пространства\n",
        "units = 1024 #задаем размер слоя(количество нейронов в слое) \n",
        "vocab_inp_size = len(inp_language_tokenizer.word_index)+1 #задаем размер русского словаря\n",
        "vocab_tar_size = len(targ_language_tokenizer.word_index)+1 #задаем размер английского словаря\n",
        "\n",
        "# Создаём датасет из массивов Numpy(рус и анг тренировочные фразы) со случайной подачей тренировочных сэмплов в процессе обучения\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "# Передаем в датасет размер батча и указываем, что если в тренировке последний батч окажется неполным, то опустим его\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# Посмотрим на форму примеров полученных батчей\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 12]), TensorShape([64, 9]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adbHk_p2cP4S"
      },
      "source": [
        "# **Создаём классы Encoder, Attention, Decoder**\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/n6vz5OZHKZ8?t=1500"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dR1pxuq8b5Xq"
      },
      "source": [
        "######################\n",
        "# Создаем класс для кодировщика Encoder\n",
        "######################\n",
        "class Encoder(Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz): #указываем атрибуты класса\n",
        "    super(Encoder, self).__init__() #даем возможность использовать и исполнять методы класса-родителя в классе потомке \n",
        "    self.batch_sz = batch_sz #атрибут возвращает размер батча\n",
        "    self.enc_units = enc_units #атрибут возвращает размер слоя в кодировщике\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim) #атрибут эмбеддинга - слой Кераса с размером словаря на входе и с dim=256\n",
        "    # Реккурентной сетью выберем GRU, указываем размер слоя, вывод из слоя в виде последовательностей, \n",
        "    # и метод инициализации весов 'glorot_uniform'(или метод Ксавьера) для упрощения прохождения сигнала при распростр-ии ошибки\n",
        "    self.gru = GRU(self.enc_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  # Метод принимает входную фразу и начальное состояние\n",
        "  def call(self, x, hidden): #при обращении к экземпляру класса как к функции, будет вызываться этот метод:\n",
        "    x = self.embedding(x) # входящие тензоры преобразовываются в эмбеддинг\n",
        "    output, state = self.gru(x, initial_state = hidden) #затем пропускаются через GRU и получаем выход + новое состояние\n",
        "    return output, state #вызов метода/функции вернёт выход из сети GRU и состояние на выходе\n",
        "\n",
        "  def initialize_hidden_state(self): #создаем метод инициализации состояний на скрытых слоях\n",
        "    return tf.zeros((self.batch_sz, self.enc_units)) #задаем начальное состояние как размер батча на размер слоя\n",
        "    \n",
        "#  input tensor(фраза в виде индексов)---->Encoder----> output(значение на выходе) и hidden_state(состояние на выходе)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPTH-Q4ObnI5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ca76029-764e-4397-931e-4c5472bd7992"
      },
      "source": [
        "# Создадим модель кодировщика по уже заданным параметрам \n",
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# Подадим в качестве примера какой-то сэмпл(Тензор[64, 12]) на вход Encoder'у и визуализируем, что получим\n",
        "\n",
        "sample_hidden = encoder.initialize_hidden_state() #инициализируем начальное скрытое состояние\n",
        "# Даем Encoder'у сэмпл и начальное состояние, и получим выход из сети GRU и состояние на выходе (вызывается метод call класса Encoder)\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Размеры выхода из кодировщика: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Размеры скрытого состояния: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Размеры выхода из кодировщика: (batch size, sequence length, units) (64, 12, 1024)\n",
            "Размеры скрытого состояния: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aORPLydpup4B"
      },
      "source": [
        "######################\n",
        "# Создаем класс Attention для внедрения механизма внимания\n",
        "######################\n",
        "class BahdanauAttention(Model): #название класса именем создателя механизма Дмитрия Богданова(Bahdanau)\n",
        "  def __init__(self, units): # создаем слой внимания из указанного кол-ва нейронов\n",
        "    super(BahdanauAttention, self).__init__() #даем возможность использовать и исполнять методы класса-родителя в классе потомке\n",
        "    self.W1 = Dense(units) #атрибут: получаем веса, пропуская через полносвязный слой\n",
        "    self.W2 = Dense(units) #атрибут: получаем веса, пропуская через полносвязный слой\n",
        "    self.V =  Dense(1) #атрибут: пропускаем через Dense с одним нейроном, получаем отдельный вес на каждый такт\n",
        "\n",
        "  def call(self, hidden_state, values): \n",
        "    # Форма состояния на скрытом слое (batch_size, hidden size)\n",
        "    # Форму состояния на каждом такте увеличим до (batch_size, 1, hidden size)\n",
        "    # Добавляем это для того, чтобы получить оценку\n",
        "    hidden_with_time_axis = tf.expand_dims(hidden_state, 1)\n",
        "\n",
        "    # Форма оценки score (размер батча, макс.длина слов на входе, 1), однёрка в конце, чтобы применить self.V\n",
        "    # До применения self.V оценка была бы (размер батча, макс.длина слов на входе, количество нейронов в слое)\n",
        "    score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "    # К полученной оценке применим Софтмакс, который покажет вероятность полезности от 0 до 1 для каждого слова в фразе для декодера\n",
        "    # Форма оценки score - (размер батча, макс.длина слов на входе, 1); Софтмакс применяем к оси \"макс.длина слов\"\n",
        "    attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "    # Построим вектор контекста \n",
        "    context_vector = attention_weights * values # веса внимания перемножим со значениями(выхода из кодировщика)\n",
        "    # Сумму также применяем по оси \"макс.длина слов на входе\"\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1) #размеры вектора контекста после суммирования будут (размер батча, размер слоя)\n",
        "\n",
        "    return context_vector, attention_weights #возвращает вектор контекста и веса внимания\n",
        "\n",
        "# encoder hidden state и  output ---->Attention Layer----> context vector(вектор контекста) и attention weights (веса внимания)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsopqJZxC_0g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61c646b0-a54c-4560-db94-38059f30c8f3"
      },
      "source": [
        "# Проверим, как работает слой\n",
        "attention_layer = BahdanauAttention(10)\n",
        "# Подадим на вход слою внимания выход из Encodera и его состояние, и получим значение и веса внимания\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Размеры значения внимания: (размер батча, размер слоя) {}\".format(attention_result.shape))\n",
        "print(\"Размеры весов внимания: (размер батча, длина последовательности, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Размеры значения внимания: (размер батча, размер слоя) (64, 1024)\n",
            "Размеры весов внимания: (размер батча, длина последовательности, 1) (64, 12, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIs1ni4-d1ZW"
      },
      "source": [
        "######################\n",
        "# Создаем класс для декодировщика Decoder\n",
        "######################\n",
        "class Decoder(Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__() #даем возможность использовать и исполнять методы класса-родителя в классе потомке \n",
        "    self.batch_sz = batch_sz #атрибут возвращает размер батча\n",
        "    self.dec_units = dec_units #атрибут возвращает размер слоя в декодере(кол-во нейронов)\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim) #атрибут эмбеддинга - слой Кераса с размером словаря на входе и (dim=256) на выходе\n",
        "\n",
        "    # Реккурентной сетью выберем GRU, указываем размер слоя, вывод из слоя в виде последовательностей, \n",
        "    # и метод инициализации весов 'glorot_uniform'(или метод Ксавьера) для упрощения прохождения сигнала при распростр-ии ошибки    \n",
        "    self.gru = GRU(self.dec_units, return_sequences=True, return_state=True, recurrent_initializer='glorot_uniform')\n",
        "    self.fc = Dense(vocab_size) #атрибут вызовет полносвязный слой с размером словаря\n",
        "\n",
        "    self.attention = BahdanauAttention(self.dec_units) #атрибут подключит механизм внимания, описанный ранее\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    # enc_output размеры (batch_size, max_length, hidden_size - размер батча, макс.длина фраз, разм.скр.слоя)\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "    # входящий тензор слова пропускаем через эмбеддинг (получаем размеры batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # дальше конкатенируем с вектором контекста (получаем размеры batch_size, 1, embedding_dim + hidden_size)\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # сконкатенированный вектор передаем  в GRU и получаем выход с декодера и состояние\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output размеры (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # пропускаем через полносвязный слой\n",
        "    x = self.fc(output) #output размеры (batch_size, vocab)\n",
        "\n",
        "    return x, state, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owtx5d6emgmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a9ecf3-7596-44e6-c353-8bc2e2eb4056"
      },
      "source": [
        "# Проверим работу декодера, подав на вход случайный массив с нужной размерностью\n",
        "# Создали декодер с параметрами(размер анг.словаря, размерность эмбеддинга, кол-во нейронов, размер батча)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "# Подаём на вход случайный массив с нужной размерностью, состояние и выход с кодировщика\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((64, 1)), sample_hidden, sample_output)\n",
        "\n",
        "print ('Размер выхода с декодера: (размер батча, размер словаря) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Размер выхода с декодера: (размер батча, размер словаря) (64, 11756)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hER8MqbaouHz"
      },
      "source": [
        "######################\n",
        "# Определяем функцию потерь\n",
        "######################\n",
        "optimizer = Adam() # из оптимизаторов кераса выбираем Adam\n",
        "# Используем SparseCategoricalCrossentropy, к-я может работать не с категориальными лейблами\n",
        "loss_object = SparseCategoricalCrossentropy(from_logits=True, reduction='none') #логит - тензор к к-му применим софтмакс\n",
        "\n",
        "def loss_function(real, pred): # Запишем функцию потерь, на вход подаем фактический и предсказанный результат\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0)) #накидываем \"маску\" которая оставит для работы ненулевые значения\n",
        "  loss_ = loss_object(real, pred) #фактические и предсказанные результаты передаем в SparseCategoricalCrossentropy и получаем ошибку\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "  \n",
        "  #reduce_mean - среднее любого выбранного тензора\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkqawSfT_5zk"
      },
      "source": [
        "# **Обучение Нейросети**\n",
        "\n",
        "*Разбор данного раздела:* https://youtu.be/n6vz5OZHKZ8?t=2075"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_DuuKi0pV2N"
      },
      "source": [
        "# Сохраняем процесс обучения модели чекпоинтами тензорфлоу\n",
        "checkpoint_dir = './training_checkpoints' #даем ссылку на директорию\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\") #добавляем префикс \"ckpt\"\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer, encoder=encoder, decoder=decoder) #сохраняем состояния/показатели оптимизатора и моделей"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW_wZQ13pd49"
      },
      "source": [
        "######################\n",
        "# Создадим функцию запуска обучения модели \n",
        "######################\n",
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden): #функция принимает тензоры(фразы в виде индексов) и состояние в кодировщике\n",
        "  loss = 0 #создаем переменную, в которую будем записывать ошибку\n",
        "\n",
        "  # Все операции по вычислению градиента записываются на ленту(tape) и мы получаем к ним доступ\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Передаем тензор и начальное состояние в кодировщик и получим выход и состояние на выходе\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden #передадим это состояние декодеру\n",
        "\n",
        "    # Передаем в качестве входа в декодер индекс токена \"<start>\"\n",
        "    dec_input = tf.expand_dims([targ_language_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Техника \"Teacher forcing\" - подаем предыдущее выходное слово на вход следущего в декодере. Targ.shape[64, 9]\n",
        "    for t in range(1, targ.shape[1]): #для каждого слова из английской фразы\n",
        "      # Передаем в обработку декодеру начальный токен, состояние на выходе из кодера, и выход из кодера\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output) # Получаем от декодера предсказание и обновленное состояние\n",
        "      # Обновляем ошибку для текущих предсказаний\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # Используем \"Teacher forcing\"\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1])) # Получаем ошибку на батче . Targ.shape[64, 9]. Делим на 9\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables # создаем переменные, для которых TensorFlow будет вычислять градиенты\n",
        "\n",
        "  gradients = tape.gradient(loss, variables) #отслеживаем градиент\n",
        "  \n",
        "  optimizer.apply_gradients(zip(gradients, variables)) #оптимизируем веса\n",
        "\n",
        "  return batch_loss #функция обучения вернет ошибку на батче"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYE7UHJT_TU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82fce986-aa4b-4cd4-dabe-a8a2a086f03e"
      },
      "source": [
        "######################\n",
        "# Запуск обучения\n",
        "######################\n",
        "EPOCHS = 30 #устанавливаем количество эпох\n",
        "\n",
        "for epoch in range(EPOCHS): #на каждой эпохе\n",
        "  start = time.time() #включаем счетчик времени\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state() #задаем начальное состояние на скрытом слое encodera\n",
        "  total_loss = 0 #начальное значение итоговой ошибки\n",
        "\n",
        "  # Для батча, входного и выходного тензора на каждом шаге эпохи\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden) #передадим в функцию тензоры и состояние в кодировщике, обучим и получим ошибку на батче\n",
        "    total_loss += batch_loss #добавим ее в итоговую ошибку\n",
        "\n",
        "  # Каждые 10 эпох будем сохранять чекпоинты\n",
        "  if (epoch + 1) % 10 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "  # Выведем показатели после каждой эпохи\n",
        "  print('Эпоха {} Ошибка {:.4f}'.format(epoch + 1, total_loss / steps_per_epoch))\n",
        "  print('Время на 1 эпоху {} сек\\n'.format(round(time.time() - start), 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Эпоха 1 Ошибка 2.1200\n",
            "Время на 1 эпоху 58 сек\n",
            "\n",
            "Эпоха 2 Ошибка 1.3229\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 3 Ошибка 0.8588\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 4 Ошибка 0.5412\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 5 Ошибка 0.3493\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 6 Ошибка 0.2365\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 7 Ошибка 0.1698\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 8 Ошибка 0.1334\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 9 Ошибка 0.1084\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 10 Ошибка 0.0937\n",
            "Время на 1 эпоху 50 сек\n",
            "\n",
            "Эпоха 11 Ошибка 0.0855\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 12 Ошибка 0.0794\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 13 Ошибка 0.0752\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 14 Ошибка 0.0712\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 15 Ошибка 0.0693\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 16 Ошибка 0.0676\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 17 Ошибка 0.0653\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 18 Ошибка 0.0618\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 19 Ошибка 0.0597\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 20 Ошибка 0.0597\n",
            "Время на 1 эпоху 50 сек\n",
            "\n",
            "Эпоха 21 Ошибка 0.0584\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 22 Ошибка 0.0578\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 23 Ошибка 0.0551\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 24 Ошибка 0.0554\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 25 Ошибка 0.0542\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 26 Ошибка 0.0516\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 27 Ошибка 0.0495\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 28 Ошибка 0.0495\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 29 Ошибка 0.0482\n",
            "Время на 1 эпоху 49 сек\n",
            "\n",
            "Эпоха 30 Ошибка 0.0485\n",
            "Время на 1 эпоху 51 сек\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFIvJfrf3Wtg"
      },
      "source": [
        "######################\n",
        "# Функция запуска и оценки модели переводчика\n",
        "######################\n",
        "def evaluate(sentence):\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp)) # создаем начальные настройки графика внимания\n",
        "\n",
        "    sentence = preprocess_sentence(sentence) #предобрабатываем предложение\n",
        "\n",
        "    inputs = [inp_language_tokenizer.word_index[i] for i in sentence.split(' ')] #преобразовываем в послед-ть индексов\n",
        "    inputs = pad_sequences([inputs], maxlen=max_length_inp, padding='post') # делаем паддинг\n",
        "    inputs = tf.convert_to_tensor(inputs) #конвертируем в тф тензор\n",
        "\n",
        "    result = '' #сюда запишем результат\n",
        "\n",
        "    hidden = [tf.zeros((1, units))] #задаем начальное состояние\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden) #передаем его и входной тензор и получаем выход с кодера и состояние\n",
        "\n",
        "    dec_hidden = enc_hidden #состояние кодера передаем в декодер\n",
        "    dec_input = tf.expand_dims([targ_language_tokenizer.word_index['<start>']], 0) #передаем на вход декодеру <start> в виде индекса\n",
        "\n",
        "    for t in range(max_length_targ): #идем по макс.длине фраз выходного языка(анг)\n",
        "        # Прогоняем через декодер входящий тензор, состояние с выхода кодера, выход с кодера\n",
        "        # Получаем результат предсказания, обновленное состояние, и веса внимания\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "        # Сохраняем веса внимания для графика\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "        # Аргмаксом вытаскиваем предсказанное слово\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        # Результат конвертируем из индекса в слово и ложим в result = ''\n",
        "        result += targ_language_tokenizer.index_word[predicted_id] + ' '\n",
        "        # Если предсказанное слово - <end>, то останавливаемся, возвращаем результаты, выводим на графике\n",
        "        if targ_language_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # предсказанное значение подается обратно в модель\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGAqYUS43vRs"
      },
      "source": [
        "# Создаем функцию для построение плота с весами внимания\n",
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    ax.matshow(attention, cmap='viridis')\n",
        "\n",
        "    fontdict = {'fontsize': 14}\n",
        "\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAmiJ_Ge3yzg"
      },
      "source": [
        "def translate(sentence): # функция принимает предложение и выводит результат с визуализацией\n",
        "    result, sentence, attention_plot = evaluate(sentence)\n",
        "\n",
        "    print('Входящая фраза: %s' % (sentence))\n",
        "    print('Предсказанный перевод: {}'.format(result))\n",
        "\n",
        "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buD6d-ZF332j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab7d539-ec62-41b0-c819-0cf5319fc532"
      },
      "source": [
        "# Воспроизведём последний сохранённый чекпоинт\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8091c02780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGvp25g64Bla",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "outputId": "ad04e8de-03cf-49ae-8c3a-1dad4f00edca"
      },
      "source": [
        "# И, наконец, переведём предложение и выведем визуализацию\n",
        "translate('давайте дружить')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Входящая фраза: <start> давайте дружить <end>\n",
            "Предсказанный перевод: let s be friends . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "iAXRWL5V35uy",
        "outputId": "54d5706e-e054-4187-9d3c-60212b8c81f9"
      },
      "source": [
        "translate('у тебя всё хорошо')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Входящая фраза: <start> у тебя всё хорошо <end>\n",
            "Предсказанный перевод: you re ok . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "id": "WCCOW_yx2LKZ",
        "outputId": "dab0105f-682b-45cb-f6be-802eb6a668d9"
      },
      "source": [
        "translate('у тебя всё хорошо?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Входящая фраза: <start> у тебя всё хорошо ? <end>\n",
            "Предсказанный перевод: are you ok ? <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "waDs1rRi3Rud",
        "outputId": "83dfff15-8881-4812-f3f8-4af50245ceaa"
      },
      "source": [
        "translate('Нефть упала в стоимости до 30 долларов за баррель')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-277e08f4e408>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Нефть упала в стоимости до 30 долларов за баррель'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-000af8b7efa7>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# функция принимает предложение и выводит результат с визуализацией\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Входящая фраза: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Предсказанный перевод: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-2834a90d302d>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#предобрабатываем предложение\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp_language_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#преобразовываем в послед-ть индексов\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# делаем паддинг\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#конвертируем в тф тензор\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-2834a90d302d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#предобрабатываем предложение\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp_language_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#преобразовываем в послед-ть индексов\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# делаем паддинг\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#конвертируем в тф тензор\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Нефть'"
          ]
        }
      ]
    }
  ]
}